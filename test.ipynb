{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "l = [1,2,3,4]\n",
    "\n",
    "p = pd.DataFrame([],columns=['a','b','c'])\n",
    "\n",
    "p.iloc[len(p),:] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_dict= {\n",
    "  \"Name\": \"Praveen Srikaram\",\n",
    "  \"Contact Number\": \"(+91)7013815534\",\n",
    "  \"Email ID\": \"praveensaikrishna7722@gmail.com\",\n",
    "  \"Phone Number\": \"(+91)7013815534\",\n",
    "  \"Skillsets\": [\n",
    "    \"Data analysis\",\n",
    "    \"Full stack development\",\n",
    "    \"Data cleansing and preprocessing\",\n",
    "    \"Creating dashboards, reports, and visualizations\",\n",
    "    \"Cloud domain knowledge\"\n",
    "  ],\n",
    "  \"Past Job Experience\": [\n",
    "    {\n",
    "      \"Company\": \"TATA CONSULTANCY SERVICES\",\n",
    "      \"Position\": \"Data Analyst-Systems Engineer\",\n",
    "      \"Duration\": \"JAN 2022 – Till date\",\n",
    "      \"Description\": \"Worked on data analysis activities which involved thorough cleansing, preprocessing and validation of data and producing timely business reports / dashboards\"\n",
    "    },\n",
    "    {\n",
    "      \"Company\": \"TATA CONSULTANCY SERVICES\",\n",
    "      \"Position\": \"Assistant Systems Engineer\",\n",
    "      \"Duration\": \"MAR 2021–FEB 2022\",\n",
    "      \"Description\": \"Worked on cloud cyber security feature called “Identity and Access Management” which involves usage of tools like One Identity, Oracle Unified Directory\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_records(resume_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata=\"We are a leading fintech company based out of Palo Alto, California. We facilitate more than a billion transactions daily. The D&A team monitors and flags fraudulent transactions. The team is looking for a data scientist who will help them sift through rich transaction data and build advanced systems to effectively mitigate fraudulent transactions.\"\n",
    "designation=\"Data scientist I\"\n",
    "min_education=\"Bachelors in engineering/ mathematics/ statistics or masters in STEM\"\n",
    "experience=\"4\"\n",
    "responsibilities=\"\"\"a. Help data ingestion from different sources like streaming data, third party data, transaction data into GCP\n",
    "b. Build executive facing dashboards by mining the data. \n",
    "c. Build fraud detection models in GCP using Kubeflow.\n",
    "d. Deploy and monitor models at scale.\n",
    "e. Present and establish findings to stakeholders.\"\"\"\n",
    "techstack=\"Python/R/C++, Google BigTable, Kubeflow, Apache Spark, Jupyter, Tensorflow, pySpark, neural networks\"\n",
    "other_tools=\"\"\n",
    "role_type=\"Permanent\"\n",
    "role_location=\"Bangalore/Hyderabad\"\n",
    "requisition_id=\"1234\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example OpenAI Python library request\n",
    "MODEL = \"gpt-3.5-turbo\"\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a recruiter for a technology company. \"},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"You are a recruiter for a technology company. You have been asked by the team to create a job description with the below details.\n",
    "            1. About the company and role: {metadata}\n",
    "            2. Designation: {designation}\n",
    "            3. Minimum educational qualifications: {min_education}. Elaborate more in detail.\n",
    "            4. Minimum years of experience required: {experience} years\n",
    "            5. Responsibilities:{responsibilities}. Elaborate on these responsibilities as per your knowledge for the role of {designation}\n",
    "            6. Technology stack experience required: {techstack}. Add one line details for each skill/tool mentioned.\n",
    "            7. Role type: {role_type}\n",
    "            8. Role location: {role_location}\n",
    "            9. Requisition ID: {requisition_id}\n",
    "            10. Other information to include in the resume: {other_tools}\n",
    "            Please add other relevant details as you may think relevant. \"\"\",\n",
    "        },\n",
    "    ],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain import PromptTemplate, HuggingFaceHub, LLMChain, OpenAI\n",
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=HuggingFaceHub(repo_id=\"google/flan-t5-xl\", model_kwargs={\"temperature\":1e-10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=\"Data scientist I\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template1 = \"\"\"Question: Let's generate a job description for {designation}\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt1 = PromptTemplate(template=template1, input_variables=[\"designation\"])\n",
    "designation=\"Data scientist I\"\n",
    "chain1 = LLMChain(llm=llm, prompt=prompt1)\n",
    "\n",
    "overall_chain = SimpleSequentialChain(chains=[chain1], verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = overall_chain.run(designation)\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parse_resume import Resume\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "engine='text-davinci-003'\n",
    "\n",
    "pdf_path='./uploads/Anupam_Misra.pdf'\n",
    "prompt = Resume(pdf_path)._createPrompt().replace('   ','')\n",
    "completions = openai.Completion.create(\n",
    "        engine=engine,\n",
    "        prompt=prompt,\n",
    "        max_tokens=2048,\n",
    "        n=1,\n",
    "        temperature=0.01,\n",
    "    )\n",
    "answer = completions.choices[0]['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_data=[x.split(':') for x in answer.split(\"\\n\\n\") if x!='']\n",
    "resume_dict=dict(zip([x[0] for x in resume_data],[x[1:] for x in resume_data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_dict['Name'][0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = resume_dict['Name'][0].strip()\n",
    "phone = resume_dict['Contact Number'][0].strip()\n",
    "email = resume_dict['Email'][0].strip()\n",
    "skills = resume_dict['Skills'][0].strip()\n",
    "past_exp = resume_dict['Past Job Experience'][0].strip()\n",
    "education = resume_dict['Education']\n",
    "certifications = resume_dict['Certifications']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.DataFrame([[1,2,3,4]],columns=['1','2','3','4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(p['1'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_resume = pd.read_csv(\"parsed_resumes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_resume.loc[parsed_resume['Name']=='Anupam Misra',:] = [1,2,3,4,5,6,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm import parseResume\n",
    "anwer,data,response=parseResume('./uploads/Anupam_Misra.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parse_resume import Resume\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "engine='text-davinci-003'\n",
    "pdf_path=\"./uploads/Anupam_Misra.pdf\"\n",
    "prompt = Resume(pdf_path)._createPrompt().replace('   ','')\n",
    "completions = openai.Completion.create(\n",
    "        engine=engine,\n",
    "        prompt=prompt,\n",
    "        max_tokens=2048,\n",
    "        n=1,\n",
    "        temperature=0.01,\n",
    "    )\n",
    "answer = completions.choices[0]['text']\n",
    "import json\n",
    "resume_dict=json.loads(answer[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Anupam Misra',\n",
       " 'contact_number': '9620216111',\n",
       " 'email_id': 'anupammisra1995@gmail.com',\n",
       " 'linkedIn_id': 'linkedin.com/in/misra-anupam',\n",
       " 'educational_background': 'PGP in Data Science from Praxis Business School, B.Tech in E&E from Manipal Institute of Technology, ISC and ICSE from St. Patrick’s H.S. School',\n",
       " 'years_of_experience': '4+',\n",
       " 'identified_job_role': 'Data Scientist',\n",
       " 'technical_skillsets': 'Python, R, HTML, CSS, JS, c3.ai, Microsoft Azure ML Studio, Azure App Services, AWS Sagemaker, AWS EC2, scikit-learn, spaCy, NLTK, genism, tensorflow, pytorch, keras, Statistical models, tree- based models, ANN, RNN, LSTM, Transformers, Autoencoders, Topic modelling, Entity recognition, Postgres, Cassandra, MongoDB',\n",
       " 'past_job_experience': 'Senior Associate at Pricewaterhouse Coopers Services LLP, Manager at Reliance Industries Limited',\n",
       " 'certifications': 'Machine learning engineering for production (specialization) – deeplearning.ai, IBM Data Science (specialization) – IBM Machine learning – Stanford university, The complete SQL bootcamp – Udemy',\n",
       " 'projects': 'MLOps using Github Actions and Azure ML Studio, Interviewbot – End-to-end interviewing solution, Analysis of the Indian education system',\n",
       " 'publication': 'Combining local and global approaches to ascertain semantic similarity published in INDISCON conference 2022 by IEEE',\n",
       " 'awards': 'Dazzling Debut award for outstanding impact within first six months of joining the firm, Two spot awards for contribution to firm and people, Academic merit rank 1, recipient of Director’s merit list scholarship, Highest scorer in Physics in ISC'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data scientist']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "parsed_resumes=pd.read_csv('./parsed_resumes.csv')\n",
    "list(parsed_resumes['Job_Role'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', ' Contact_Number', ' Email_ID', ' Skillsets',\n",
       "       ' Past_Job_Experience', ' Education', ' Certifications', ' Job_Role',\n",
       "       ' YOE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_resumes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd=\"\"\"About the Company and Role:\n",
    "Our company is a leading technology company specializing in cutting-edge solutions and innovative products. As a Data Scientist, you will join our dynamic and highly skilled team dedicated to driving data-driven insights and delivering impactful solutions. In this role, you will have the opportunity to work with cross-functional teams, collaborate on challenging projects, and contribute to the growth and success of the company.\n",
    "\n",
    "Designation: Data Scientist\n",
    "\n",
    "Minimum Educational Qualifications:\n",
    "\n",
    "Bachelor's degree in Computer Science, Statistics, Mathematics, or a related field. A strong understanding of statistical concepts and algorithms is essential.\n",
    "Minimum Years of Experience Required: 4+ years of relevant industry experience in data science, machine learning, or a related field.\n",
    "\n",
    "Responsibilities:\n",
    "\n",
    "Create Models: Develop and implement machine learning models and algorithms to solve complex business problems. This involves data exploration, feature engineering, model selection, and evaluation.\n",
    "Data Wrangling: Gather, clean, preprocess, and transform data from various sources. Perform data analysis and ensure data quality for effective model training and inference.\n",
    "Model Maintenance: Continuously monitor, evaluate, and refine models to improve performance and adapt to changing data patterns. Implement best practices for model versioning and deployment.\n",
    "MLOPS: Collaborate with DevOps and engineering teams to build scalable and automated machine learning pipelines. Implement tools and frameworks for model deployment, monitoring, and maintenance.\n",
    "Technology Stack Experience Required:\n",
    "\n",
    "Python: Proficiency in Python programming language for data manipulation, analysis, and modeling. Experience with Pandas and Numpy libraries for efficient data processing and numerical operations.\n",
    "Operating Systems (OS): Familiarity with various operating systems (e.g., Linux, Windows) and the command-line interface for managing and executing data science workflows.\n",
    "JSON: Knowledge of JSON (JavaScript Object Notation) for data interchange and configuration purposes.\n",
    "Role Type: Full-Time Employment (FTE)\n",
    "\n",
    "Role Location: Bengaluru, India\n",
    "\n",
    "Requisition ID: 11673393\n",
    "\n",
    "Other Information to Include in the Resume:\n",
    "\n",
    "Proficiency in Python data science libraries (e.g., Pandas, Numpy) for data manipulation and analysis.\n",
    "Strong analytical and problem-solving skills.\n",
    "Excellent communication and collaboration abilities.\n",
    "Experience in data visualization and storytelling.\n",
    "Familiarity with machine learning frameworks (e.g., TensorFlow, PyTorch) is a plus.\n",
    "Knowledge of SQL and databases is beneficial.\n",
    "Advanced degree (Master's or Ph.D.) in a related field is preferred.\"\"\"\n",
    "\n",
    "prompt = f\"\"\"You are a Specialist Recruiter. Your job is to make a python list of technical skillsets ,extracting from the job description written within the $ delimiter. Do not write anything out of context. ${jd}$ \"\"\"\n",
    "completions = openai.Completion.create(\n",
    "        engine='text-davinci-003',\n",
    "        prompt=prompt,\n",
    "        max_tokens=2048,\n",
    "        n=1,\n",
    "        temperature=0.01,\n",
    "    )\n",
    "answer = completions.choices[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills=[x.strip('\\n') for x in answer.split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python',\n",
       " ' Pandas',\n",
       " ' Numpy',\n",
       " ' Linux',\n",
       " ' Windows',\n",
       " ' JSON',\n",
       " ' SQL',\n",
       " ' TensorFlow',\n",
       " ' PyTorch',\n",
       " ' Data Visualization',\n",
       " ' Storytelling',\n",
       " ' Analytical and Problem-Solving Skills',\n",
       " ' Communication and Collaboration Abilities']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_resumes=pd.read_csv('./parsed_resumes.csv')\n",
    "job_roles=list(parsed_resumes['Job_Role'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data scientist', 'Data engineer']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_to_look_at = parsed_resumes.loc[parsed_resumes['Job_Role'] == job_roles,['Name','Skillsets','Certifications','Education','Past_Job_Experience']] # May error out need to test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_data=\"\"\"\"\"\"\n",
    "for i, v in enumerate(candidates_to_look_at.values):\n",
    "    # candidate_data+=\n",
    "    candidate_data+=str(i+1)+\". \"+v[0]+\" :: \"+\"; \".join(v[1:])+\" \\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Anupam Misra :: Python, R, HTML, CSS, JS, c3.ai, Microsoft Azure ML Studio, Azure App Services, AWS Sagemaker, AWS EC2, scikit-learn, spaCy, NLTK, genism, tensorflow, pytorch, keras etc.; Machine learning engineering for production (specialization) – deeplearning.ai, IBM Data Science (specialization) – IBM Machine learning – Stanford university, The complete SQL bootcamp – Udemy; PGP in Data Science: CQPI 7.12/8 from Praxis Business School, B.Tech in E&E: CGPA 8.59/10 from Manipal Institute of Technology, ISC: 92.20%, ICSE: 90.43% from St. Patrick’s H.S. School; Senior Associate at Pricewaterhouse Coopers Services LLP (Nov. 2021 - present), Manager at Reliance Industries Limited (July 2018 – Jan. 2021) \n",
      "2. Anupam Mitra :: Python, R, HTML, CSS, JS, c3.ai, Microsoft Azure ML Studio, Azure App Services, AWS Sagemaker, AWS EC2, scikit-learn, spaCy, NLTK, genism, tensorflow, pytorch, keras etc.; Machine learning engineering for production (specialization) – deeplearning.ai, IBM Data Science (specialization) – IBM Machine learning – Stanford university, The complete SQL bootcamp – Udemy; PGP in Data Science: CQPI 7.12/8 from Praxis Business School, B.Tech in E&E: CGPA 8.59/10 from Manipal Institute of Technology, ISC: 92.20%, ICSE: 90.43% from St. Patrick’s H.S. School; Senior Associate at Pricewaterhouse Coopers Services LLP (Nov. 2021 - present), Manager at Reliance Industries Limited (July 2018 – Jan. 2021) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(candidate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Anupam Misra :: Python, R, HTML, CSS, JS, c3.ai, Microsoft Azure ML Studio, Azure App Services, AWS Sagemaker, AWS EC2, scikit-learn, spaCy, NLTK, genism, tensorflow, pytorch, keras etc.; Machine learning engineering for production (specialization) – deeplearning.ai, IBM Data Science (specialization) – IBM Machine learning – Stanford university, The complete SQL bootcamp – Udemy; PGP in Data Science: CQPI 7.12/8 from Praxis Business School, B.Tech in E&E: CGPA 8.59/10 from Manipal Institute of Technology, ISC: 92.20%, ICSE: 90.43% from St. Patrick’s H.S. School; Senior Associate at Pricewaterhouse Coopers Services LLP (Nov. 2021 - present), Manager at Reliance Industries Limited (July 2018 – Jan. 2021) \\n2. Anupam Mitra :: Python, R, HTML, CSS, JS, c3.ai, Microsoft Azure ML Studio, Azure App Services, AWS Sagemaker, AWS EC2, scikit-learn, spaCy, NLTK, genism, tensorflow, pytorch, keras etc.; Machine learning engineering for production (specialization) – deeplearning.ai, IBM Data Science (specialization) – IBM Machine learning – Stanford university, The complete SQL bootcamp – Udemy; PGP in Data Science: CQPI 7.12/8 from Praxis Business School, B.Tech in E&E: CGPA 8.59/10 from Manipal Institute of Technology, ISC: 92.20%, ICSE: 90.43% from St. Patrick’s H.S. School; Senior Associate at Pricewaterhouse Coopers Services LLP (Nov. 2021 - present), Manager at Reliance Industries Limited (July 2018 – Jan. 2021) \\n'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "identified_skillsets_from_jd=\"python, mlops, google analytics, power bi, machine learning\"\n",
    "selected_roles=\"data engineer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are a professional recruiter for technical companies. You will be given skills and job roles to evaluate different candidates given their names, skillsets, certifications, education and past job experience. Your job will be mention the skills which are there for each candidate and to assign scores between 1 to 100 to against each candidate. Do not assign scores to skills. The candidates with the most relevant skillsets to the job role  shall be given highest score.  The skills to check are within %. The job role is given within $ delimiter and the details of candidates are given within the # delimiter. The scores shall be printed just after the list of identified skills against each candidate. Start only with the answer. Don't justify the reason behind the scoring.\n",
    "\n",
    "%{identified_skillsets_from_jd}%\n",
    "\n",
    "$ The job role is of {\",\".join(selected_roles)} $\n",
    "\n",
    "#{candidate_data}#\n",
    "\"\"\"\n",
    "\n",
    "completions = openai.Completion.create(\n",
    "        engine=engine,\n",
    "        prompt=prompt,\n",
    "        max_tokens=2048,\n",
    "        n=1,\n",
    "        temperature=0,\n",
    "    )\n",
    "answer = completions.choices[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Anupam Misra :: Python, MLOps, Google Analytics, Power BI, Machine Learning; Score: 95\n",
      "2. Anupam Mitra :: Python, MLOps, Google Analytics, Power BI, Machine Learning; Score: 95\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "model=\"gpt-3.5-turbo\",\n",
    "messages=[\n",
    "    # {\"role\": \"system\", \"content\": \"You are an experienced recruiter in a technology company having in-depth knowledge of different technical roles and their responsibilities.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt,\n",
    "    },\n",
    "],\n",
    "temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=response.choices[0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Anupam Misra: \\nSkills: Python, machine learning\\nScore: 80\\n\\nAnupam Mitra: \\nSkills: Python, machine learning\\nScore: 80'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "eachline=[x.split('\\n') for x in answer.split(\"\\n\\n\")]\n",
    "eachline_v2=[[y.split(\":\") for y in x] for x in eachline]\n",
    "recom=pd.DataFrame(eachline_v2, columns=[\"Name\",\"Found skills\",\"Score\"])\n",
    "recom=recom.applymap(lambda x: ''.join(x))\n",
    "recom['Found skills']=recom['Found skills'].apply(lambda x: x[7:])\n",
    "recom['Score']=recom['Score'].apply(lambda x: x[6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Found skills</th>\n",
       "      <th>Score</th>\n",
       "      <th>Found Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anupam Misra</td>\n",
       "      <td>Python, machine learning</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anupam Mitra</td>\n",
       "      <td>Python, machine learning</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name              Found skills Score Found Score\n",
       "0  Anupam Misra   Python, machine learning    80          80\n",
       "1  Anupam Mitra   Python, machine learning    80          80"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], []]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[[y[1::2]] for y in x] for x in eachline_v2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
