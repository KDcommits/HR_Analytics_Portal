{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "l = [1,2,3,4]\n",
    "\n",
    "p = pd.DataFrame([],columns=['a','b','c'])\n",
    "\n",
    "p.iloc[len(p),:] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_dict= {\n",
    "  \"Name\": \"Praveen Srikaram\",\n",
    "  \"Contact Number\": \"(+91)7013815534\",\n",
    "  \"Email ID\": \"praveensaikrishna7722@gmail.com\",\n",
    "  \"Phone Number\": \"(+91)7013815534\",\n",
    "  \"Skillsets\": [\n",
    "    \"Data analysis\",\n",
    "    \"Full stack development\",\n",
    "    \"Data cleansing and preprocessing\",\n",
    "    \"Creating dashboards, reports, and visualizations\",\n",
    "    \"Cloud domain knowledge\"\n",
    "  ],\n",
    "  \"Past Job Experience\": [\n",
    "    {\n",
    "      \"Company\": \"TATA CONSULTANCY SERVICES\",\n",
    "      \"Position\": \"Data Analyst-Systems Engineer\",\n",
    "      \"Duration\": \"JAN 2022 – Till date\",\n",
    "      \"Description\": \"Worked on data analysis activities which involved thorough cleansing, preprocessing and validation of data and producing timely business reports / dashboards\"\n",
    "    },\n",
    "    {\n",
    "      \"Company\": \"TATA CONSULTANCY SERVICES\",\n",
    "      \"Position\": \"Assistant Systems Engineer\",\n",
    "      \"Duration\": \"MAR 2021–FEB 2022\",\n",
    "      \"Description\": \"Worked on cloud cyber security feature called “Identity and Access Management” which involves usage of tools like One Identity, Oracle Unified Directory\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_records(resume_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata=\"We are a leading fintech company based out of Palo Alto, California. We facilitate more than a billion transactions daily. The D&A team monitors and flags fraudulent transactions. The team is looking for a data scientist who will help them sift through rich transaction data and build advanced systems to effectively mitigate fraudulent transactions.\"\n",
    "designation=\"Data scientist I\"\n",
    "min_education=\"Bachelors in engineering/ mathematics/ statistics or masters in STEM\"\n",
    "experience=\"4\"\n",
    "responsibilities=\"\"\"a. Help data ingestion from different sources like streaming data, third party data, transaction data into GCP\n",
    "b. Build executive facing dashboards by mining the data. \n",
    "c. Build fraud detection models in GCP using Kubeflow.\n",
    "d. Deploy and monitor models at scale.\n",
    "e. Present and establish findings to stakeholders.\"\"\"\n",
    "techstack=\"Python/R/C++, Google BigTable, Kubeflow, Apache Spark, Jupyter, Tensorflow, pySpark, neural networks\"\n",
    "other_tools=\"\"\n",
    "role_type=\"Permanent\"\n",
    "role_location=\"Bangalore/Hyderabad\"\n",
    "requisition_id=\"1234\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example OpenAI Python library request\n",
    "MODEL = \"gpt-3.5-turbo\"\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a recruiter for a technology company. \"},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"You are a recruiter for a technology company. You have been asked by the team to create a job description with the below details.\n",
    "            1. About the company and role: {metadata}\n",
    "            2. Designation: {designation}\n",
    "            3. Minimum educational qualifications: {min_education}. Elaborate more in detail.\n",
    "            4. Minimum years of experience required: {experience} years\n",
    "            5. Responsibilities:{responsibilities}. Elaborate on these responsibilities as per your knowledge for the role of {designation}\n",
    "            6. Technology stack experience required: {techstack}. Add one line details for each skill/tool mentioned.\n",
    "            7. Role type: {role_type}\n",
    "            8. Role location: {role_location}\n",
    "            9. Requisition ID: {requisition_id}\n",
    "            10. Other information to include in the resume: {other_tools}\n",
    "            Please add other relevant details as you may think relevant. \"\"\",\n",
    "        },\n",
    "    ],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain import PromptTemplate, HuggingFaceHub, LLMChain, OpenAI\n",
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=HuggingFaceHub(repo_id=\"google/flan-t5-xl\", model_kwargs={\"temperature\":1e-10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=\"Data scientist I\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template1 = \"\"\"Question: Let's generate a job description for {designation}\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt1 = PromptTemplate(template=template1, input_variables=[\"designation\"])\n",
    "designation=\"Data scientist I\"\n",
    "chain1 = LLMChain(llm=llm, prompt=prompt1)\n",
    "\n",
    "overall_chain = SimpleSequentialChain(chains=[chain1], verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = overall_chain.run(designation)\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parse_resume import Resume\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "engine='text-davinci-003'\n",
    "\n",
    "pdf_path='./uploads/Anupam_Misra.pdf'\n",
    "prompt = Resume(pdf_path)._createPrompt().replace('   ','')\n",
    "completions = openai.Completion.create(\n",
    "        engine=engine,\n",
    "        prompt=prompt,\n",
    "        max_tokens=2048,\n",
    "        n=1,\n",
    "        temperature=0.01,\n",
    "    )\n",
    "answer = completions.choices[0]['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_data=[x.split(':') for x in answer.split(\"\\n\\n\") if x!='']\n",
    "resume_dict=dict(zip([x[0] for x in resume_data],[x[1:] for x in resume_data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_dict['Name'][0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = resume_dict['Name'][0].strip()\n",
    "phone = resume_dict['Contact Number'][0].strip()\n",
    "email = resume_dict['Email'][0].strip()\n",
    "skills = resume_dict['Skills'][0].strip()\n",
    "past_exp = resume_dict['Past Job Experience'][0].strip()\n",
    "education = resume_dict['Education']\n",
    "certifications = resume_dict['Certifications']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.DataFrame([[1,2,3,4]],columns=['1','2','3','4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(p['1'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_resume = pd.read_csv(\"parsed_resumes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_resume.loc[parsed_resume['Name']=='Anupam Misra',:] = [1,2,3,4,5,6,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm import parseResume\n",
    "anwer,data,response=parseResume('./uploads/Anupam_Misra.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parse_resume import Resume\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "engine='text-davinci-003'\n",
    "pdf_path=\"./uploads/Anupam_Misra.pdf\"\n",
    "prompt = Resume(pdf_path)._createPrompt().replace('   ','')\n",
    "completions = openai.Completion.create(\n",
    "        engine=engine,\n",
    "        prompt=prompt,\n",
    "        max_tokens=2048,\n",
    "        n=1,\n",
    "        temperature=0.01,\n",
    "    )\n",
    "answer = completions.choices[0]['text']\n",
    "resume_data=[x.split(':') for x in answer.split(\"\\n\\n\") if x!='']\n",
    "resume_dict=dict(zip([x[0] for x in resume_data],[x[1:] for x in resume_data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "resume_dict=json.loads(answer[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Anupam Misra',\n",
       " 'contact_number': '9620216111',\n",
       " 'email_id': 'anupammisra1995@gmail.com',\n",
       " 'linkedIn_id': 'linkedin.com/in/misra-anupam',\n",
       " 'educational_background': 'PGP in Data Science from Praxis Business School, B.Tech in E&E from Manipal Institute of Technology, ISC from St. Patrick’s H.S. School',\n",
       " 'identified_job_role': 'Data Scientist',\n",
       " 'technical_skillsets': 'Python, R, HTML, CSS, JS, c3.ai, Microsoft Azure ML Studio, Azure App Services, AWS Sagemaker, AWS EC2, scikit-learn, spaCy, NLTK, genism, tensorflow, pytorch, keras, Statistical models, tree- based models, ANN, RNN, LSTM, Transformers, Autoencoders, Topic modelling, Entity recognition, Postgres, Cassandra, MongoDB',\n",
       " 'past_job_experience': 'Senior Associate at Pricewaterhouse Coopers Services LLP, Manager at Reliance Industries Limited',\n",
       " 'certifications': 'Machine learning engineering for production (specialization) – deeplearning.ai, IBM Data Science (specialization) – IBM Machine learning – Stanford university, The complete SQL bootcamp – Udemy',\n",
       " 'projects': 'MLOps using Github Actions and Azure ML Studio, Interviewbot – End-to-end interviewing solution, Analysis of the Indian education system',\n",
       " 'publication': 'Combining local and global approaches to ascertain semantic similarity published in INDISCON conference 2022 by IEEE',\n",
       " 'awards': 'Dazzling Debut award for outstanding impact within first six months of joining the firm, Two spot awards for contribution to firm and people, Academic merit rank 1, recipient of Director’s merit list scholarship'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    resume_dict=json.loads(answer[10:])\n",
    "    name = resume_dict['name']\n",
    "    phone = resume_dict['contact_number']\n",
    "    email = resume_dict['email_id']\n",
    "    skills = resume_dict['technical_skillsets']\n",
    "    past_exp = resume_dict['past_job_experience']\n",
    "    education = resume_dict['educational_background']\n",
    "    certifications = resume_dict['certifications']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
