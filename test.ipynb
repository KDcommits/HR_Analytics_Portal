{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "l = [1,2,3,4]\n",
    "\n",
    "p = pd.DataFrame([],columns=['a','b','c'])\n",
    "\n",
    "p.iloc[len(p),:] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_dict= {\n",
    "  \"Name\": \"Praveen Srikaram\",\n",
    "  \"Contact Number\": \"(+91)7013815534\",\n",
    "  \"Email ID\": \"praveensaikrishna7722@gmail.com\",\n",
    "  \"Phone Number\": \"(+91)7013815534\",\n",
    "  \"Skillsets\": [\n",
    "    \"Data analysis\",\n",
    "    \"Full stack development\",\n",
    "    \"Data cleansing and preprocessing\",\n",
    "    \"Creating dashboards, reports, and visualizations\",\n",
    "    \"Cloud domain knowledge\"\n",
    "  ],\n",
    "  \"Past Job Experience\": [\n",
    "    {\n",
    "      \"Company\": \"TATA CONSULTANCY SERVICES\",\n",
    "      \"Position\": \"Data Analyst-Systems Engineer\",\n",
    "      \"Duration\": \"JAN 2022 – Till date\",\n",
    "      \"Description\": \"Worked on data analysis activities which involved thorough cleansing, preprocessing and validation of data and producing timely business reports / dashboards\"\n",
    "    },\n",
    "    {\n",
    "      \"Company\": \"TATA CONSULTANCY SERVICES\",\n",
    "      \"Position\": \"Assistant Systems Engineer\",\n",
    "      \"Duration\": \"MAR 2021–FEB 2022\",\n",
    "      \"Description\": \"Worked on cloud cyber security feature called “Identity and Access Management” which involves usage of tools like One Identity, Oracle Unified Directory\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_records(resume_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata=\"We are a leading fintech company based out of Palo Alto, California. We facilitate more than a billion transactions daily. The D&A team monitors and flags fraudulent transactions. The team is looking for a data scientist who will help them sift through rich transaction data and build advanced systems to effectively mitigate fraudulent transactions.\"\n",
    "designation=\"Data scientist I\"\n",
    "min_education=\"Bachelors in engineering/ mathematics/ statistics or masters in STEM\"\n",
    "experience=\"4\"\n",
    "responsibilities=\"\"\"a. Help data ingestion from different sources like streaming data, third party data, transaction data into GCP\n",
    "b. Build executive facing dashboards by mining the data. \n",
    "c. Build fraud detection models in GCP using Kubeflow.\n",
    "d. Deploy and monitor models at scale.\n",
    "e. Present and establish findings to stakeholders.\"\"\"\n",
    "techstack=\"Python/R/C++, Google BigTable, Kubeflow, Apache Spark, Jupyter, Tensorflow, pySpark, neural networks\"\n",
    "other_tools=\"\"\n",
    "role_type=\"Permanent\"\n",
    "role_location=\"Bangalore/Hyderabad\"\n",
    "requisition_id=\"1234\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example OpenAI Python library request\n",
    "MODEL = \"gpt-3.5-turbo\"\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a recruiter for a technology company. \"},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"You are a recruiter for a technology company. You have been asked by the team to create a job description with the below details.\n",
    "            1. About the company and role: {metadata}\n",
    "            2. Designation: {designation}\n",
    "            3. Minimum educational qualifications: {min_education}. Elaborate more in detail.\n",
    "            4. Minimum years of experience required: {experience} years\n",
    "            5. Responsibilities:{responsibilities}. Elaborate on these responsibilities as per your knowledge for the role of {designation}\n",
    "            6. Technology stack experience required: {techstack}. Add one line details for each skill/tool mentioned.\n",
    "            7. Role type: {role_type}\n",
    "            8. Role location: {role_location}\n",
    "            9. Requisition ID: {requisition_id}\n",
    "            10. Other information to include in the resume: {other_tools}\n",
    "            Please add other relevant details as you may think relevant. \"\"\",\n",
    "        },\n",
    "    ],\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain import PromptTemplate, HuggingFaceHub, LLMChain, OpenAI\n",
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=HuggingFaceHub(repo_id=\"google/flan-t5-xl\", model_kwargs={\"temperature\":1e-10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=\"Data scientist I\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template1 = \"\"\"Question: Let's generate a job description for {designation}\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt1 = PromptTemplate(template=template1, input_variables=[\"designation\"])\n",
    "designation=\"Data scientist I\"\n",
    "chain1 = LLMChain(llm=llm, prompt=prompt1)\n",
    "\n",
    "overall_chain = SimpleSequentialChain(chains=[chain1], verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = overall_chain.run(designation)\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parse_resume import Resume\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "engine='text-davinci-003'\n",
    "\n",
    "# pdf_path='./uploads/Anupam_Misra.pdf'\n",
    "# prompt = Resume(pdf_path)._createPrompt().replace('   ','')\n",
    "# completions = openai.Completion.create(\n",
    "#         engine=engine,\n",
    "#         prompt=prompt,\n",
    "#         max_tokens=2048,\n",
    "#         n=1,\n",
    "#         temperature=0.01,\n",
    "#     )\n",
    "# answer = completions.choices[0]['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_data=[x.split(':') for x in answer.split(\"\\n\\n\") if x!='']\n",
    "resume_dict=dict(zip([x[0] for x in resume_data],[x[1:] for x in resume_data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_dict['Name'][0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = resume_dict['Name'][0].strip()\n",
    "phone = resume_dict['Contact Number'][0].strip()\n",
    "email = resume_dict['Email'][0].strip()\n",
    "skills = resume_dict['Skills'][0].strip()\n",
    "past_exp = resume_dict['Past Job Experience'][0].strip()\n",
    "education = resume_dict['Education']\n",
    "certifications = resume_dict['Certifications']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.DataFrame([[1,2,3,4]],columns=['1','2','3','4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(p['1'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_resume = pd.read_csv(\"parsed_resumes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_resume.loc[parsed_resume['Name']=='Anupam Misra',:] = [1,2,3,4,5,6,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm import parseResume\n",
    "anwer,data,response=parseResume('./uploads/Anupam_Misra.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parse_resume import Resume\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "# engine='text-davinci-003'\n",
    "# pdf_path=\"./uploads/Anupam_Misra.pdf\"\n",
    "# prompt = Resume(pdf_path)._createPrompt().replace('   ','')\n",
    "# completions = openai.Completion.create(\n",
    "#         engine=engine,\n",
    "#         prompt=prompt,\n",
    "#         max_tokens=2048,\n",
    "#         n=1,\n",
    "#         temperature=0.01,\n",
    "#     )\n",
    "# answer = completions.choices[0]['text']\n",
    "# import json\n",
    "# resume_dict=json.loads(answer[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "parsed_resumes=pd.read_csv('./parsed_resumes.csv')\n",
    "list(parsed_resumes['Job_Role'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_resumes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jd=\"\"\"About the Company and Role:\n",
    "Our company is a leading technology company specializing in cutting-edge solutions and innovative products. As a Data Scientist, you will join our dynamic and highly skilled team dedicated to driving data-driven insights and delivering impactful solutions. In this role, you will have the opportunity to work with cross-functional teams, collaborate on challenging projects, and contribute to the growth and success of the company.\n",
    "\n",
    "Designation: Data Scientist\n",
    "\n",
    "Minimum Educational Qualifications:\n",
    "\n",
    "Bachelor's degree in Computer Science, Statistics, Mathematics, or a related field. A strong understanding of statistical concepts and algorithms is essential.\n",
    "Minimum Years of Experience Required: 4+ years of relevant industry experience in data science, machine learning, or a related field.\n",
    "\n",
    "Responsibilities:\n",
    "\n",
    "Create Models: Develop and implement machine learning models and algorithms to solve complex business problems. This involves data exploration, feature engineering, model selection, and evaluation.\n",
    "Data Wrangling: Gather, clean, preprocess, and transform data from various sources. Perform data analysis and ensure data quality for effective model training and inference.\n",
    "Model Maintenance: Continuously monitor, evaluate, and refine models to improve performance and adapt to changing data patterns. Implement best practices for model versioning and deployment.\n",
    "MLOPS: Collaborate with DevOps and engineering teams to build scalable and automated machine learning pipelines. Implement tools and frameworks for model deployment, monitoring, and maintenance.\n",
    "Technology Stack Experience Required:\n",
    "\n",
    "Python: Proficiency in Python programming language for data manipulation, analysis, and modeling. Experience with Pandas and Numpy libraries for efficient data processing and numerical operations.\n",
    "Operating Systems (OS): Familiarity with various operating systems (e.g., Linux, Windows) and the command-line interface for managing and executing data science workflows.\n",
    "JSON: Knowledge of JSON (JavaScript Object Notation) for data interchange and configuration purposes.\n",
    "Role Type: Full-Time Employment (FTE)\n",
    "\n",
    "Role Location: Bengaluru, India\n",
    "\n",
    "Requisition ID: 11673393\n",
    "\n",
    "Other Information to Include in the Resume:\n",
    "\n",
    "Proficiency in Python data science libraries (e.g., Pandas, Numpy) for data manipulation and analysis.\n",
    "Strong analytical and problem-solving skills.\n",
    "Excellent communication and collaboration abilities.\n",
    "Experience in data visualization and storytelling.\n",
    "Familiarity with machine learning frameworks (e.g., TensorFlow, PyTorch) is a plus.\n",
    "Knowledge of SQL and databases is beneficial.\n",
    "Advanced degree (Master's or Ph.D.) in a related field is preferred.\"\"\"\n",
    "\n",
    "prompt = f\"\"\"You are a Specialist Recruiter. Your job is to make a python list of technical skillsets ,extracting from the job description written within the $ delimiter. Do not write anything out of context. ${jd}$ \"\"\"\n",
    "completions = openai.Completion.create(\n",
    "        engine='text-davinci-003',\n",
    "        prompt=prompt,\n",
    "        max_tokens=2048,\n",
    "        n=1,\n",
    "        temperature=0.01,\n",
    "    )\n",
    "answer = completions.choices[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills=[x.strip('\\n') for x in answer.split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_resumes=pd.read_csv('./parsed_resumes.csv')\n",
    "job_roles=list(parsed_resumes['Job_Role'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_to_look_at = parsed_resumes.loc[parsed_resumes['Job_Role'] == job_roles,['Name','Skillsets','Certifications','Education','Past_Job_Experience']] # May error out need to test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_data=\"\"\"\"\"\"\n",
    "for i, v in enumerate(candidates_to_look_at.values):\n",
    "    # candidate_data+=\n",
    "    candidate_data+=str(i+1)+\". \"+v[0]+\" :: \"+\"; \".join(v[1:])+\" \\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(candidate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identified_skillsets_from_jd=\"python, mlops, google analytics, power bi, machine learning\"\n",
    "selected_roles=\"data engineer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are a professional recruiter for technical companies. You will be given skills and job roles to evaluate different candidates given their names, skillsets, certifications, education and past job experience. Your job will be mention the skills which are there for each candidate and to assign scores between 1 to 100 to against each candidate. Do not assign scores to skills. The candidates with the most relevant skillsets to the job role  shall be given highest score.  The skills to check are within %. The job role is given within $ delimiter and the details of candidates are given within the # delimiter. The scores shall be printed just after the list of identified skills against each candidate. Start only with the answer. Don't justify the reason behind the scoring.\n",
    "\n",
    "%{identified_skillsets_from_jd}%\n",
    "\n",
    "$ The job role is of {\",\".join(selected_roles)} $\n",
    "\n",
    "#{candidate_data}#\n",
    "\"\"\"\n",
    "\n",
    "# completions = openai.Completion.create(\n",
    "#         engine=engine,\n",
    "#         prompt=prompt,\n",
    "#         max_tokens=2048,\n",
    "#         n=1,\n",
    "#         temperature=0,\n",
    "#     )\n",
    "# answer = completions.choices[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "model=\"gpt-3.5-turbo\",\n",
    "messages=[\n",
    "    # {\"role\": \"system\", \"content\": \"You are an experienced recruiter in a technology company having in-depth knowledge of different technical roles and their responsibilities.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt,\n",
    "    },\n",
    "],\n",
    "temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=response.choices[0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eachline=[x.split('\\n') for x in answer.split(\"\\n\\n\")]\n",
    "eachline_v2=[[y.split(\":\") for y in x] for x in eachline]\n",
    "recom=pd.DataFrame(eachline_v2, columns=[\"Name\",\"Found skills\",\"Score\"])\n",
    "recom=recom.applymap(lambda x: ''.join(x))\n",
    "recom['Found skills']=recom['Found skills'].apply(lambda x: x[7:])\n",
    "recom['Score']=recom['Score'].apply(lambda x: x[6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[[y[1::2]] for y in x] for x in eachline_v2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Contact_Number</th>\n",
       "      <th>Email_ID</th>\n",
       "      <th>Skillsets</th>\n",
       "      <th>Past_Job_Experience</th>\n",
       "      <th>Education</th>\n",
       "      <th>Certifications</th>\n",
       "      <th>Job_Role</th>\n",
       "      <th>YOE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anupam Misra</td>\n",
       "      <td>9620216111</td>\n",
       "      <td>anupammisra1995@gmail.com</td>\n",
       "      <td>Python, R, HTML, CSS, JS, c3.ai, Microsoft Azu...</td>\n",
       "      <td>Senior Associate at Pricewaterhouse Coopers Se...</td>\n",
       "      <td>PGP in Data Science: CQPI 7.12/8 from Praxis B...</td>\n",
       "      <td>Machine learning engineering for production (s...</td>\n",
       "      <td>ML engineer</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Krishnendu Dey</td>\n",
       "      <td>1123456789</td>\n",
       "      <td>krishnendu.dey@gmail.com</td>\n",
       "      <td>Python, R, HTML, CSS, JS, c3.ai, Microsoft Azu...</td>\n",
       "      <td>Associate at Pricewaterhouse Coopers Services ...</td>\n",
       "      <td>-</td>\n",
       "      <td>Microsoft Azure data scientist, c3.ai data sci...</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aishwarya Chougule</td>\n",
       "      <td>4534534534</td>\n",
       "      <td>aishwarys@gmail.com</td>\n",
       "      <td>Power BI, Tableau, Power BI DAX, SQL, MongoDB,...</td>\n",
       "      <td>Associate at Pricewaterhouse Coopers Services ...</td>\n",
       "      <td>-</td>\n",
       "      <td>Power BI developer, Tableau certified developer</td>\n",
       "      <td>BI developer</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Radha Rathore</td>\n",
       "      <td>3453534535</td>\n",
       "      <td>radha12@gmail.com</td>\n",
       "      <td>Python, R, scikit-learn, Power BI, Tableau, py...</td>\n",
       "      <td>Senior Associate at Pricewaterhouse Coopers Se...</td>\n",
       "      <td>-</td>\n",
       "      <td>Azure certified data architect, AWS data archi...</td>\n",
       "      <td>Data engineer</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geetha Joseph</td>\n",
       "      <td>7978943553</td>\n",
       "      <td>joseph.geetha@gmail.com</td>\n",
       "      <td>pYSpark, LSTM, ARIMA, VARIMAX, Prophet, scikit...</td>\n",
       "      <td>Senior Associate at Pricewaterhouse Coopers Se...</td>\n",
       "      <td>-</td>\n",
       "      <td>AWS data solutions engineer, Azure certified d...</td>\n",
       "      <td>Data engineer</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Uttam Kumar</td>\n",
       "      <td>5456544443</td>\n",
       "      <td>ukumar@gmail.com</td>\n",
       "      <td>Power BI, SQL, MS Excel, Python, scikit-learn,...</td>\n",
       "      <td>Intern at Pricewaterhouse Coopers Services LLP...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Barkha Bharti</td>\n",
       "      <td>4344442223</td>\n",
       "      <td>barkha.ml@gmail.com</td>\n",
       "      <td>NLP, NLG, PyTorch, tensor flow, python, R, sci...</td>\n",
       "      <td>Senior Associate at Pricewaterhouse Coopers Se...</td>\n",
       "      <td>-</td>\n",
       "      <td>Microsoft Azure data scientist, SQL certified ...</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Aditya Maurya</td>\n",
       "      <td>4556345457</td>\n",
       "      <td>aditya.maurya@gmail.com</td>\n",
       "      <td>Python, HTML, R, CSS, JS, bootstrap, Azure ML ...</td>\n",
       "      <td>Associate at Pricewaterhouse Coopers Services ...</td>\n",
       "      <td>-</td>\n",
       "      <td>Certified Tensorflow developer, Microsoft cert...</td>\n",
       "      <td>ML architect</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name  Contact_Number                   Email_ID  \\\n",
       "0        Anupam Misra      9620216111  anupammisra1995@gmail.com   \n",
       "1      Krishnendu Dey      1123456789   krishnendu.dey@gmail.com   \n",
       "2  Aishwarya Chougule      4534534534        aishwarys@gmail.com   \n",
       "3       Radha Rathore      3453534535          radha12@gmail.com   \n",
       "4       Geetha Joseph      7978943553    joseph.geetha@gmail.com   \n",
       "5         Uttam Kumar      5456544443           ukumar@gmail.com   \n",
       "6       Barkha Bharti      4344442223        barkha.ml@gmail.com   \n",
       "7       Aditya Maurya      4556345457    aditya.maurya@gmail.com   \n",
       "\n",
       "                                           Skillsets  \\\n",
       "0  Python, R, HTML, CSS, JS, c3.ai, Microsoft Azu...   \n",
       "1  Python, R, HTML, CSS, JS, c3.ai, Microsoft Azu...   \n",
       "2  Power BI, Tableau, Power BI DAX, SQL, MongoDB,...   \n",
       "3  Python, R, scikit-learn, Power BI, Tableau, py...   \n",
       "4  pYSpark, LSTM, ARIMA, VARIMAX, Prophet, scikit...   \n",
       "5  Power BI, SQL, MS Excel, Python, scikit-learn,...   \n",
       "6  NLP, NLG, PyTorch, tensor flow, python, R, sci...   \n",
       "7  Python, HTML, R, CSS, JS, bootstrap, Azure ML ...   \n",
       "\n",
       "                                 Past_Job_Experience  \\\n",
       "0  Senior Associate at Pricewaterhouse Coopers Se...   \n",
       "1  Associate at Pricewaterhouse Coopers Services ...   \n",
       "2  Associate at Pricewaterhouse Coopers Services ...   \n",
       "3  Senior Associate at Pricewaterhouse Coopers Se...   \n",
       "4  Senior Associate at Pricewaterhouse Coopers Se...   \n",
       "5  Intern at Pricewaterhouse Coopers Services LLP...   \n",
       "6  Senior Associate at Pricewaterhouse Coopers Se...   \n",
       "7  Associate at Pricewaterhouse Coopers Services ...   \n",
       "\n",
       "                                           Education  \\\n",
       "0  PGP in Data Science: CQPI 7.12/8 from Praxis B...   \n",
       "1                                                  -   \n",
       "2                                                  -   \n",
       "3                                                  -   \n",
       "4                                                  -   \n",
       "5                                                  -   \n",
       "6                                                  -   \n",
       "7                                                  -   \n",
       "\n",
       "                                      Certifications        Job_Role  YOE  \n",
       "0  Machine learning engineering for production (s...     ML engineer    4  \n",
       "1  Microsoft Azure data scientist, c3.ai data sci...  Data scientist    3  \n",
       "2    Power BI developer, Tableau certified developer    BI developer    4  \n",
       "3  Azure certified data architect, AWS data archi...   Data engineer    5  \n",
       "4  AWS data solutions engineer, Azure certified d...   Data engineer    5  \n",
       "5                                                  -  Data scientist    3  \n",
       "6  Microsoft Azure data scientist, SQL certified ...  Data scientist    1  \n",
       "7  Certified Tensorflow developer, Microsoft cert...    ML architect    4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llm import _identify_candidates_by_job_role\n",
    "parsed_resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_resumes\n",
    "selected_roles=[\"Data scientist\",\"ML engineer\"]\n",
    "candidates_to_look_at = parsed_resumes.loc[parsed_resumes['Job_Role'].isin(selected_roles),['Skillsets','Certifications','Education','YOE']].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Python, R, HTML, CSS, JS, c3.ai, Microsoft Azure ML Studio, Azure App Services, AWS Sagemaker, AWS EC2, scikit-learn, spaCy, NLTK, genism, tensorflow, pytorch, keras etc.',\n",
       "        'Machine learning engineering for production (specialization)  deeplearning.ai, IBM Data Science (specialization)  IBM Machine learning  Stanford university, The complete SQL bootcamp  Udemy',\n",
       "        'PGP in Data Science: CQPI 7.12/8 from Praxis Business School, B.Tech in E&E: CGPA 8.59/10 from Manipal Institute of Technology, ISC: 92.20%, ICSE: 90.43% from St. Patricks H.S. School',\n",
       "        4],\n",
       "       ['Python, R, HTML, CSS, JS, c3.ai, Microsoft Azure ML Studio, Azure App Services, scikit-learn, spaCy, NLTK, genism, tensorflow, pytorch, keras, pinecone, langchain. CNN',\n",
       "        'Microsoft Azure data scientist, c3.ai data science, MongoDB certified developer',\n",
       "        '-', 3],\n",
       "       ['Power BI, SQL, MS Excel, Python, scikit-learn, NLP, Computer vision, Resnet-50, ANN, deep learning, sentiment analysis',\n",
       "        '-', '-', 3],\n",
       "       ['NLP, NLG, PyTorch, tensor flow, python, R, scikit-learn, Power BI, keras, Microsoft Azure, AWS Sagemaker, Google Colab',\n",
       "        'Microsoft Azure data scientist, SQL certified developer, AWS certified data scientist',\n",
       "        '-', 1]], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates_to_look_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "candidate_data=\"\"\"\"\"\"\n",
    "print(candidate_data)\n",
    "for i, v in enumerate(candidates_to_look_at):\n",
    "    candidate_data+=str(i+1)+\". \"\n",
    "    candidate_data+=str(v[0])\n",
    "    candidate_data+=\" :: \"\n",
    "    candidate_data+=\"; \".join(str(x) for x in v[1:])\n",
    "    candidate_data+=\" \\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm import _identify_candidates_by_job_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ML engineer', 'Data scientist']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "identified_skillsets_from_jd=[\"python\",\"mlops\",\"machine learning\",\"azure\"]\n",
    "selected_roles=[\"ML engineer\",\"Data scientist\"]\n",
    "candidate_data = _identify_candidates_by_job_role(parsed_resumes,selected_roles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = f\"\"\"\n",
    "You are a professional recruiter for technical companies. You will be given skills and job roles to evaluate different candidates given their names, skillsets, certifications, education and past job experience. Your job will be mention the skills which are there for each candidate and to assign scores between 1 to 100 to against each candidate. The candidates with the most relevant skillsets to the job role  shall be given highest score.  The skills to check are within %. The job role is given within $ delimiter and the details of candidates are given within the # delimiter. The scores shall be assigned just after the list of identified skills for each candidate. Start only with the answer. Don't justify the reason behind the scoring.\n",
    "\n",
    "%{identified_skillsets_from_jd}%\n",
    "\n",
    "$ The job role is of {\",\".join(selected_roles)} $\n",
    "\n",
    "#{candidate_data}#\"\"\"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "model=\"gpt-3.5-turbo\",\n",
    "messages=[\n",
    "    {\"role\": \"user\", \"content\": prompt,\n",
    "    },\n",
    "],\n",
    "temperature=0,\n",
    ")\n",
    "answer = response.choices[0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Skills: Python, Microsoft Azure ML Studio, Azure App Services, scikit-learn, spaCy, NLTK, genism, tensorflow, pytorch, keras\\nScore: 90\\n\\n2. Skills: Python, Microsoft Azure ML Studio, Azure App Services, scikit-learn, spaCy, NLTK, genism, tensorflow, pytorch, keras\\nScore: 85\\n\\n3. Skills: Python, scikit-learn, NLP, Computer vision, deep learning\\nScore: 70\\n\\n4. Skills: Python, PyTorch, tensorflow, scikit-learn, keras, Microsoft Azure, AWS Sagemaker\\nScore: 80'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "eachline=[x.split('\\n') for x in answer.split(\"\\n\\n\")]\n",
    "eachline_v2=[[y.split(\":\") for y in x] for x in eachline]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['1. Skills',\n",
       "   ' Python, Microsoft Azure ML Studio, Azure App Services, scikit-learn, spaCy, NLTK, genism, tensorflow, pytorch, keras'],\n",
       "  ['Score', ' 90']],\n",
       " [['2. Skills',\n",
       "   ' Python, Microsoft Azure ML Studio, Azure App Services, scikit-learn, spaCy, NLTK, genism, tensorflow, pytorch, keras'],\n",
       "  ['Score', ' 85']],\n",
       " [['3. Skills', ' Python, scikit-learn, NLP, Computer vision, deep learning'],\n",
       "  ['Score', ' 70']],\n",
       " [['4. Skills',\n",
       "   ' Python, PyTorch, tensorflow, scikit-learn, keras, Microsoft Azure, AWS Sagemaker'],\n",
       "  ['Score', ' 80']]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eachline_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['1. Skills', ' Python, Microsoft Azure ML Studio, Azure App Services, scikit-learn, spaCy, NLTK, genism, tensorflow, pytorch, keras'], ['Score', ' 90']], [['2. Skills', ' Python, Microsoft Azure ML Studio, Azure App Services, scikit-learn, spaCy, NLTK, genism, tensorflow, pytorch, keras'], ['Score', ' 85']], [['3. Skills', ' Python, scikit-learn, NLP, Computer vision, deep learning'], ['Score', ' 70']], [['4. Skills', ' Python, PyTorch, tensorflow, scikit-learn, keras, Microsoft Azure, AWS Sagemaker'], ['Score', ' 80']]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(eachline_v2)\n",
    "recom=pd.DataFrame(eachline_v2, columns=[\"Found skills\",\"Score\"])\n",
    "recom=recom.applymap(lambda x: ''.join(x))\n",
    "recom['Found skills']=recom['Found skills'].apply(lambda x: x[7:])\n",
    "recom['Score']=recom['Score'].apply(lambda x: x[6:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Found skills</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ls Python, Microsoft Azure ML Studio, Azure Ap...</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ls Python, Microsoft Azure ML Studio, Azure Ap...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ls Python, scikit-learn, NLP, Computer vision,...</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ls Python, PyTorch, tensorflow, scikit-learn, ...</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Found skills Score\n",
       "0  ls Python, Microsoft Azure ML Studio, Azure Ap...    90\n",
       "1  ls Python, Microsoft Azure ML Studio, Azure Ap...    85\n",
       "2  ls Python, scikit-learn, NLP, Computer vision,...    70\n",
       "3  ls Python, PyTorch, tensorflow, scikit-learn, ...    80"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recom[\"Name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
